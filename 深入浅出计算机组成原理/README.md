[TOC]



# 深入浅出计算机组成原理

## 01 冯·诺伊曼体系结构：计算机组成的金字塔

### 1.1 计算机的基本硬件组成
计算机硬件基本组成：CPU、内存和主板。

1. CPU 是计算机最重要的核心配件，全称`中央处理器（Center Processing Unit）`。计算机的所有“计算”都是由 CPU 完成的。
2. 应用程序要加载到内存（Memory）中才能运行，程序读取的数据、计算得到的结果也要放到内存中。存放在内存里的程序和数据，需要被 CPU 读取，CPU 计算完之后，还要把数据写回到内存。
3. 主板（Motherboard）是一个有着各种各样，有时达到数十甚至上百个插槽的配件。主板的**芯片组（Chipset）**和**总线（Bus）**解决了 CPU 和内存之间如何通信的问题。芯片组控制了数据传输的流转，也就是数据从哪里到哪里的问题。总线则是实际数据传输的高速公路。因此，总线速度（Bus Speed）决定了数据能传输得多快。
4. I/O 设备。显示器是输出设备，鼠标、键盘是输入设备。
5. 电源
6. 硬盘为了永久保存数据。

### 1.2 冯·诺伊曼体系结构
冯·诺依曼体系结构（Von Neumann architecture），也叫存储程序计算机。

什么是存储程序计算机呢？这里面其实暗含了两个概念，一个是**“可编程”**计算机，一个是**“存储”**计算机。

![](https://github.com/CPythoner/GeekTime/blob/master/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/images/1.2.jpg?raw=true)

1. 首先是一个包含算术逻辑单元（Arithmetic Logic Unit，ALU）和处理器寄存器（Processor Register）的**处理器单元**（Processing Unit），用来完成各种算术和逻辑运算。因为它能够完成各种数据的处理或者计算工作，因此也有人把这个叫作数据通路（Datapath）或者运算器。
2. 然后是一个包含指令寄存器（Instruction Reigster）和程序计数器（Program Counter）的**控制器单元**（Control Unit/CU），用来控制程序的流程，通常就是不同条件下的分支和跳转。在现在的计算机里，上面的算术逻辑单元和这里的控制器单元，共同组成了我们说的 CPU。
3. 接着是用来存储数据（Data）和指令（Instruction）的**内存**。以及更大容量的**外部存储**，在过去，可能是磁带、磁鼓这样的设备，现在通常就是硬盘。
4. 最后就是各种**输入和输出设备**，以及对应的输入和输出机制。

所有的计算机程序，也都可以抽象为从输入设备读取输入信息，通过运算器和控制器来执行存储在存储器里的程序，最终把结果输出到输出设备中。而我们所有撰写的无论高级还是低级语言的程序，也都是基于这样一个抽象框架来进行运作的。

## 02 给你一张知识地图：计算机组成原理应该这么学
![](https://github.com/CPythoner/GeekTime/blob/master/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/images/2.0.jpg?raw=true)

### 2.1 计算机组成原理知识地图
把整个计算机组成原理的知识点拆分成了四大部分，分别是**计算机的基本组成**、**计算机的指令和计算**、**处理器设计**，以及**存储器和 I/O 设备**。

### 2.2 学习方法
1. 学会提问来串联知识点；
2. 写一些示例来验证知识点；
3. 通过和计算机硬件发展的历史做对照。

### 2.3 书籍推荐（由浅入深）
* 《计算机是怎样跑起来的》
* 《程序是怎样跑起来的》
* [Computer Organization](https://www.coursera.org/learn/jisuanji-zucheng)
* 《计算机组成与设计：硬件 / 软件接口》
* 《深入理解计算机系统》
* 《计算机组成：结构化方法》
* 《计算机体系结构：量化研究方法》
* 《编码：隐匿在计算机软硬件背后的语言》
* 《程序员的自我修养：链接、装载和库》

## 03. 通过你的 CPU 主频，我们来谈谈“性能”究竟是什么？
学习和研究计算机组成原理，就是在理解计算机是怎么运作的，以及为什么要这么运作。“为什么”所要解决的事情，很多时候就是提升“性能”。

### 3.1 什么是性能？时间的倒数
衡量计算机性能的标准：
* **响应时间**（Response time）或者叫**执行时间**（Execution time），是指执行一个程序到底需要花多长时间，花的时间越少，性能越好。要提升响应时间这个性能指标，你可以理解为让计算机“跑得更快”。
* **吞吐率**（Throughput）或者**带宽**（Bandwidth），指我们在一定的时间范围内，到底能处理多少事情。这里的“事情”，在计算机里就是处理的数据或者执行的程序指令。想要提升这个指标，你可以理解为让计算机“搬得更多”。

我们一般把性能定义成响应时间的倒数，也就是：**性能 = 1 / 响应时间**

### 3.2 计算机的计时单位：CPU 时钟
Linux 系统下执行 time 命令。它会返回三个值，第一个是**real time**，也就是我们说的 Wall Clock Time，也就是运行程序整个过程中流逝掉的时间；第二个是**user time**，也就是 CPU 在运行你的程序，在用户态运行指令的时间；第三个是**sys time**，是 CPU 在运行你的程序，在操作系统内核里运行指令的时间。而程序实际花费的 CPU 执行时间（CPU Time），就是 user time 加上 sys time。

影响时间准确性的因素：
* CPU 的运行状态：满载或降频
* 主板、内存等硬件的影响。

对 CPU 执行时间进行拆分：
**程序的 CPU 执行时间 =CPU 时钟周期数×时钟周期时间**

时钟周期时间  = 1 / CPU 主频

对于 CPU 时钟周期数，可以再做一个分解，把它变成“指令数×每条指令的平均时钟周期数（Cycles Per Instruction，简称 CPI）”。

**程序的 CPU 执行时间 = 指令数×CPI×Clock Cycle Time**

通过以上公式，可以得出优化程序的三个方法： 提升计算机主频，优化 CPU 设计使得在单个时钟周期内能够执行更多指令，以及通过编译器来减少需要的指令数。

## 04. 穿越功耗墙，我们该从哪些方面提升性能？
CPU 的主频变化时代在奔腾4进入瓶颈期，其障碍是**功耗**。
![](https://github.com/CPythoner/GeekTime/blob/master/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/images/4.0.png?raw=true)

CPU 一般都被叫作超大规模集成电路（Very-Large-Scale Integration，VLSI）。

想要计算得快，一方面，我们要在 CPU 里，同样的面积里面，多放一些晶体管，也就是**增加密度**；另一方面，我们要让晶体管“打开”和“关闭”得更快一点，也就是**提升主频**。而这两者，都会增加功耗，带来耗电和散热的问题。

一个 CPU 的功率，可以用这样一个公式来表示：
`功耗 ~= 1/2 ×负载电容×电压的平方×开关频率×晶体管数量`


### 并行优化
通过并行提高性能，也就是多核 CPU 。

**阿姆达尔定律（Amdahl’s Law）** 说的就是，对于一个程序进行优化之后，处理器并行运算之后效率提升的情况。具体可以用这样一个公式来表示：
`优化后的执行时间 = 受优化影响的执行时间 / 加速倍数 + 不受影响的执行时间`

无论提升 CPU 主频还是增加 CPU 核心数，都会遇到瓶颈，除了这两种方案，还有其他几个原则性的性能提升方法：
1. **加速大概率事件**，例如使用 GPU 和 TPU 缩短深度学习的的时间。
2. **通过流水线提升性能**，把 CPU 指令执行的过程进行拆分，细化运行，也是现代 CPU 在主频没有办法提升那么多的情况下，性能仍然可以得到提升的重要原因之一。
3. **通过预测提升性能**，通过预先猜测下一步该干什么，而不是等上一步运行的结果，提前进行运算，也是让程序跑得更快一点的办法。

## 05. 计算机指令：让我们试试用纸袋编程
计算机或者说 CPU 本身没有能力理解高级编程语言，现代计算机也只能处理“机器码”，也就是一连串的 0 和 1。

### 5.1 在软硬件接口中，CPU 帮我们做了什么事？
从**硬件**角度看， CPU 是一个超大规模集成电路，通过电路实现了加法、乘法乃至各种各样的处理逻辑。

从**软件**工程师角度看，CPU 就是执行各种计算机指令（Instruction Code）的逻辑机器。这些计算机指令被称为**机器语言**（Machine Language）。不同 CPU 支持的机器语言不同，比如 Intel 和 ARM ，不同的机器语言称为**计算指令集**（Instruction Code）。

程序指令存储在存储器里面的计算机，我们就叫作**存储程序型计算机**（Stored-program Computer）。

### 5.2 从编译到汇编，代码怎么变成机器码？
程序要在系统上跑起来，需要把整个程序翻译成**汇编语言**（ASM，Assembly Language）的程序，这个过程叫做编译（Compile）成汇编程序。

针对汇编代码，我们可以再用**汇编器**（Assembler）翻译成机器码（Machine Code）。这些机器码由“0”和“1”组成的机器语言表示。这一条条机器码，就是一条条的计算机指令。这样一串串的 16 进制数字，就是我们 CPU 能够真正认识的计算机指令。

![](https://github.com/CPythoner/GeekTime/blob/master/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/images/5.2.png?raw=true)

### 5.3 解析指令和机器码
常见的指令分类：
* **算术类指令**，加减乘除等；
* **数据传输类指令**，给变量赋值、在内存里读写数据等；
* **逻辑类指令**，逻辑上的或与非等；
* **条件分支类指令**，if/else等；
* **无条件跳转指令**，调用函数等。
![](https://github.com/CPythoner/GeekTime/blob/master/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/images/5.3.jpg?raw=true)

最简单的 MIPS 指令集，MIPS 指令是一个 32 位的整数，高六位叫做**操作码**（Opcode），剩下的 26 位有 3 种格式，分别是 **R、I 和 J**。
* R 指令一般用做算数和逻辑操作，里面有读取和输入数据的寄存器的地址。如果是逻辑位移操作，后面还有位移操作的位移量，而最后的功能码，则是在前面的操作码不够的时候，扩展操作码表示对应的具体指令的。
* I 指令通常用在数据传输、条件分支，以及在运算的时候使用的并给变量或常数的时候。这个时候没有了位移量和操作码，也没有了第三个寄存器，而是把这三部分直接合并成了一个地址或者一个常数。
* J 指令就是一个跳转指令，高六位之外的 26 位都是一个跳转后的地址。